{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mxz76JPddeli"},"outputs":[],"source":["import profile\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn.utils.prune as prune\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch.optim.lr_scheduler\n","from torchvision import datasets, transforms\n","from torch.optim.lr_scheduler import StepLR\n","from torch.autograd import Variable\n","from torch.utils.data import random_split\n","from torchvision.models import alexnet\n","from torch.utils.tensorboard import SummaryWriter\n","import time\n","import random\n","import math\n","# torch.cuda.set_per_process_memory_fraction(0.8)\n","import sys"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oHTnbbRnsFBJ"},"outputs":[],"source":["class Flatten(nn.Module):\n","    def forward(self, x):\n","        return x.view(x.size(0), -1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H6y2nI9odl-4"},"outputs":[],"source":["writer=SummaryWriter(\"trial/v4-l2/third\")\n","random_seed=42\n","torch.manual_seed(random_seed)\n","random.seed(random_seed)\n","np.random.seed(random_seed)\n","train_batch_size = 32\n","test_batch_size=32\n","num_classes = 100\n","learning_rate = 0.001\n","num_epochs = 100\n","lambda_l2 = 0.00001\n","pruning_amount = 0.2\n","\n","\n","best_model = None\n","best_accuracy = 0.0\n","\n","pruning_epochs = 10\n","pruning_rate = 0.05\n","lambda_l1 = 0.0001\n","# lambda_train=0.00001\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","if torch.cuda.is_available():\n","   torch.cuda.manual_seed_all(random_seed)\n","   device=torch.device(\"cuda\")\n","else:\n","   device=torch.device(\"cpu\")\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","\n","train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","train_size = int(0.9 * len(train_dataset))\n","val_size = len(train_dataset) - train_size\n","test_size = len(test_dataset)\n","\n","train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=2)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=2)\n","valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=test_batch_size, shuffle=False, num_workers=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UsLIN4s3djKM"},"outputs":[],"source":["\n","class Bottleneck(nn.Module):\n","    def __init__(self, in_planes, growth_rate):\n","        super(Bottleneck, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.conv1 = nn.Conv2d(in_planes, 4*growth_rate, kernel_size=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(4*growth_rate)\n","        self.conv2 = nn.Conv2d(4*growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n","\n","    def forward(self, x):\n","        out = self.conv1(F.relu(self.bn1(x)))\n","        out = self.conv2(F.relu(self.bn2(out)))\n","        out = torch.cat([out,x], 1)\n","        return out\n","\n","\n","class Transition(nn.Module):\n","    def __init__(self, in_planes, out_planes):\n","        super(Transition, self).__init__()\n","        self.bn = nn.BatchNorm2d(in_planes)\n","        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=1, bias=False)\n","\n","    def forward(self, x):\n","        out = self.conv(F.relu(self.bn(x)))\n","        out = F.avg_pool2d(out, 2)\n","        return out\n","\n","\n","class DenseNet(nn.Module):\n","    def __init__(self, block, nblocks, growth_rate=12, reduction=0.5, num_classes=10):\n","        super(DenseNet, self).__init__()\n","        self.growth_rate = growth_rate\n","\n","        num_planes = 2*growth_rate\n","        self.conv1 = nn.Conv2d(3, num_planes, kernel_size=3, padding=1, bias=False)\n","\n","        self.dense1 = self._make_dense_layers(block, num_planes, nblocks[0])\n","        num_planes += nblocks[0]*growth_rate\n","        out_planes = int(math.floor(num_planes*reduction))\n","        self.trans1 = Transition(num_planes, out_planes)\n","        num_planes = out_planes\n","\n","        self.dense2 = self._make_dense_layers(block, num_planes, nblocks[1])\n","        num_planes += nblocks[1]*growth_rate\n","        out_planes = int(math.floor(num_planes*reduction))\n","        self.trans2 = Transition(num_planes, out_planes)\n","        num_planes = out_planes\n","\n","        self.dense3 = self._make_dense_layers(block, num_planes, nblocks[2])\n","        num_planes += nblocks[2]*growth_rate\n","        out_planes = int(math.floor(num_planes*reduction))\n","        self.trans3 = Transition(num_planes, out_planes)\n","        num_planes = out_planes\n","\n","        self.dense4 = self._make_dense_layers(block, num_planes, nblocks[3])\n","        num_planes += nblocks[3]*growth_rate\n","\n","        self.bn = nn.BatchNorm2d(num_planes)\n","        self.linear = nn.Linear(num_planes, num_classes)\n","\n","    def _make_dense_layers(self, block, in_planes, nblock):\n","        layers = []\n","        for i in range(nblock):\n","            layers.append(block(in_planes, self.growth_rate))\n","            in_planes += self.growth_rate\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.trans1(self.dense1(out))\n","        out = self.trans2(self.dense2(out))\n","        out = self.trans3(self.dense3(out))\n","        out = self.dense4(out)\n","        out = F.avg_pool2d(F.relu(self.bn(out)), 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","model=DenseNet(Bottleneck, [6,12,24,16], growth_rate=32)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cKBT4eYjd-lh"},"outputs":[],"source":["model\n","# last_layer=model.linear"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"njFztj8hfCs5"},"outputs":[],"source":["def evaluate(model, valid_loader, criterion):\n","    model.eval()\n","    total_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in valid_loader:\n","            images, labels = data\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            total_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    loss = total_loss / len(valid_loader)\n","    accuracy = 100 * correct / total\n","    return loss, accuracy\n","\n","def calculate_l1_norm_of_filters(model):\n","  l1_normalisation_values={}\n","  for name,layer in model.named_children():\n","    if isinstance(layer,nn.Conv2d):\n","      print(f\"{layer} is being l1 norm found\")\n","      filters=layer.weight\n","      l1_norm_of_filter=[]\n","      for idx,filter in enumerate(filters):\n","        l1_norm=torch.sum(torch.abs(filter)).item()\n","        l1_norm_of_filter.append(l1_norm)\n","      l1_normalisation_values[name]=l1_norm_of_filter\n","  print(f\"\\n\\nThe original l1 norms for this is {l1_normalisation_values}\\n\\n\\n\")\n","  return l1_normalisation_values\n","\n","def calculate_threshold_l1_norm_of_filters(l1_normalisation_values,percentage_to_prune):\n","  threshold_values={}\n","  for filter in l1_normalisation_values:\n","    filter_values=l1_normalisation_values[filter]\n","    sorted_filter_values=sorted(filter_values)\n","    threshold_index=int(len(filter_values)*percentage_to_prune)\n","    threshold_value=sorted_filter_values[threshold_index]\n","    threshold_values[filter]=threshold_value\n","  return threshold_values\n","\n","def index_remove(tensor, dim, index, removed=False):\n","    if tensor.is_cuda:\n","        tensor = tensor.cpu()\n","    size_ = list(tensor.size())\n","    # print(f\"The size of the tensor was {size_}\")\n","    new_size = tensor.size(dim) - len(index)\n","    # print(f\"The new size of the tensor is {new_size}\")\n","    size_[dim] = new_size\n","    new_size = size_\n","\n","    select_index = list(set(range(tensor.size(dim))) - set(index))\n","    # print(f\"The selected index sizes are {len(select_index)}\")\n","    new_tensor = torch.index_select(tensor, dim, torch.tensor(select_index))\n","\n","    if removed:\n","        return new_tensor, torch.index_select(tensor, dim, torch.tensor(index))\n","\n","    return new_tensor\n","\n","def get_new_conv(in_channels, conv, dim, channel_index, independent_prune_flag=False):\n","  # print(f\"Doing for the layer {conv}\")\n","  # print(f\"Layer has {conv.in_channels} and should have {in_channels} as in channels\")\n","  # print(f\"Layer has {conv.out_channels} and should have {int(conv.out_channels - len(channel_index))} as in channels\")\n","\n","  new_conv = torch.nn.Conv2d(in_channels=in_channels,\n","                                   out_channels=int(conv.out_channels - len(channel_index)),\n","                                   kernel_size=conv.kernel_size,\n","                                   stride=conv.stride, padding=conv.padding, dilation=conv.dilation)\n","\n","  new_conv.weight.data = index_remove(conv.weight.data, 0, channel_index)\n","  # print(f\"The layer {conv} has {len(new_conv.weight)} weights now \")\n","  # new_conv.bias.data = index_remove(conv.bias.data, 0, channel_index)\n","  # print(f\"The layer {conv} has {len(new_conv.bias)} bias now \")\n","\n","  return new_conv\n","\n","def calculate_l1_norm_of_outputs(model):\n","    l1_normalisation_values = {}\n","    for name, layer in model.named_children():\n","        if isinstance(layer, nn.Linear):\n","            weights = layer.weight\n","            l1_norm_of_neurons = torch.sum(torch.abs(weights), dim=1).tolist()\n","            l1_normalisation_values[name] = l1_norm_of_neurons\n","            # print(f\"Layer {name} (Neurons): L1 norm length is {len(l1_normalisation_values[name])}\")\n","    return l1_normalisation_values\n","\n","# Calculate L1 norm of inputs\n","def calculate_l1_norm_of_inputs(model):\n","    l1_normalisation_values = {}\n","    for name, layer in model.named_children():\n","        if isinstance(layer, nn.Linear):\n","            weights = layer.weight\n","            l1_norm_of_inputs = torch.sum(torch.abs(weights), dim=0).tolist()\n","            l1_normalisation_values[name] = l1_norm_of_inputs\n","            # print(f\"Layer {name} (Inputs): L1 norm length is {len(l1_normalisation_values[name])}\")\n","    return l1_normalisation_values\n","\n","# Calculate threshold L1 norm\n","def calculate_threshold_l1_norm(values, percentage_to_prune):\n","    threshold_values = {}\n","    for layer_name, vals in values.items():\n","        sorted_vals = sorted(vals)\n","        threshold_index = int(len(sorted_vals) * percentage_to_prune)\n","        threshold_value = sorted_vals[threshold_index]\n","        threshold_values[layer_name] = threshold_value\n","    return threshold_values\n","\n","# Prune layer\n","def prune_layer(layer, outputs_to_prune, inputs_to_prune):\n","    in_features = layer.in_features - len(inputs_to_prune)\n","    out_features = layer.out_features - len(outputs_to_prune)\n","\n","    new_linear_layer = nn.Linear(in_features, out_features, bias=True)\n","\n","    keep_outputs = list(set(range(layer.out_features)) - set(outputs_to_prune))\n","    keep_inputs = list(set(range(layer.in_features)) - set(inputs_to_prune))\n","\n","    # print(f\"Pruning Layer: Keep neurons {keep_neurons}, Keep inputs {keep_inputs}\")\n","\n","    new_linear_layer.weight.data = layer.weight.data[keep_outputs][:, keep_inputs]\n","    new_linear_layer.bias.data = layer.bias.data[keep_outputs]\n","\n","    return new_linear_layer\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tAsA-ejxfMGJ"},"outputs":[],"source":["\n","# l1_norm_outputs = calculate_l1_norm_of_outputs(model)\n","# l1_norm_inputs = calculate_l1_norm_of_inputs(model)\n","# threshold_outputs = calculate_threshold_l1_norm(l1_norm_outputs, pruning_rate)\n","# threshold_inputs = calculate_threshold_l1_norm(l1_norm_inputs, pruning_rate)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1UON3UxVfNYY"},"outputs":[],"source":["\n","# filters_to_remove=[]\n","# def prune_filters(model,threshold_values,l1_norm_inputs,l1_norm_outputs,threshold_inputs,threshold_outputs):\n","#   next_channel=3\n","#   for name,layer in model.named_children():\n","#     filters_to_remove=[]\n","#     if isinstance(layer,nn.Conv2d):\n","#       filters=layer.weight\n","#       num_filters_to_prune=0\n","\n","#       for idx, filter in enumerate(filters):\n","#         l1_norm = torch.sum(torch.abs(filter)).item()\n","#         if l1_norm \u003c threshold_values[name]:\n","#           num_filters_to_prune+=1\n","#           layer.weight.data[idx].zero_()\n","#           filters_to_remove.append(idx)\n","\n","#       if num_filters_to_prune \u003e 0:\n","#         in_channels = next_channel\n","#         out_channels = layer.out_channels - num_filters_to_prune\n","#         new_conv_layer=get_new_conv(in_channels,layer,0,filters_to_remove).to(device)\n","#         setattr(model, name, new_conv_layer)\n","#         next_channel=out_channels\n","\n","#     elif isinstance(layer, nn.BatchNorm2d):\n","#       new_batch_norm_2d_layer=nn.BatchNorm2d(num_features=next_channel).to(device)\n","#       setattr(model,name,new_batch_norm_2d_layer)\n","#       del new_batch_norm_2d_layer\n","\n","#     elif isinstance(layer, nn.Linear):\n","#           if layer==last_layer:\n","#             outputs_to_prune=[]\n","#           else:\n","#             outputs_to_prune = [idx for idx, l1 in enumerate(l1_norm_outputs[name]) if l1 \u003c threshold_outputs[name]]\n","#           inputs_to_prune = [idx for idx, l1 in enumerate(l1_norm_inputs[name]) if l1 \u003c threshold_inputs[name]]\n","#           new_layer= prune_layer(layer, outputs_to_prune, inputs_to_prune)\n","#           setattr(model, name, new_layer)\n","#   return model\n","\n","\n","# def check_pruning(model):\n","#   print(\"\\nLayer and filter sizes \\n ------------------------------------\")\n","#   for name,module in model.named_modules():\n","#     if isinstance(module,nn.Conv2d):\n","#       print(f\"Layer: {name}, Filter Size: {module.out_channels}\")\n","\n","\n","# print(f\"Model is on device: {next(model.parameters()).device}\")\n","# rand_input=torch.randn(1,3,244,244).to(device)\n","# # writer.add_graph(model,rand_input)\n","\n","# total_step = len(train_loader)\n","\n","\n","# writer.add_text(\"Lambda valye\",f\"The lambda is {lambda_l1}\",0)\n","# def update_inputs_channels(model):\n","#   prev_channels=3\n","#   for name,module in model.named_children():\n","#     if isinstance(module,nn.Conv2d):\n","#       in_channels=prev_channels\n","#       module.weight.data = module.weight.data[:, :in_channels, :, :]\n","#       module.in_channels=in_channels\n","#       prev_channels=module.out_channels\n","#   return model\n","\n","# def prune_model(model,pruning_rate,l1_norm_inputs,l1_norm_outputs,threshold_inputs,threshold_outputs):\n","#    l1_norm_values=calculate_l1_norm_of_filters(model)\n","#    threshold_values=calculate_threshold_l1_norm_of_filters(l1_norm_values,pruning_rate)\n","#    model=prune_filters(model,threshold_values,l1_norm_inputs,l1_norm_outputs,threshold_inputs,threshold_outputs)\n","#    model=update_inputs_channels(model)\n","#    return model\n","\n","def print_remaining_filters(model):\n","   print(\"\\nThe filters are \\n -----------------------------------\")\n","   for name,module in model.named_modules():\n","      if isinstance(module,nn.Conv2d):\n","         print(f\"{name} has {module.out_channels} remaining filters\")\n","\n","def print_conv_layer_shapes(model):\n","    print(\"\\nLayer and shape of the filters \\n -----------------------------\")\n","    for name, module in model.named_modules():\n","        if isinstance(module, nn.Conv2d):\n","            print(f\"Conv layer: {name}, Weight shape: {module.weight.shape}  Bias shape: {module.bias.shape if module.bias is not None else 'No bias'}\")\n","\n","def calculate_regularization_loss(model):\n","    regularization_loss = 0\n","    for name, layer in model.named_children():\n","        if isinstance(layer, nn.Conv2d):\n","            filters = layer.weight\n","            for filter in filters:\n","                l2_norm = torch.norm(filter, p=2)\n","                regularization_loss += l2_norm\n","    return regularization_loss\n","\n","def custom_loss(outputs, labels, model, criterion, lambda_l1):\n","    l1_norm = 0\n","    for param in model.parameters():\n","        l1_norm += torch.sum(torch.abs(param))\n","    # Cross-entropy loss\n","    ce_loss = criterion(outputs, labels)\n","    # Total loss with L1 regularization\n","    total_loss = ce_loss - lambda_l1 * l1_norm\n","    return total_loss\n","\n","\n","def print_loss_and_custom_loss(outputs, labels, model, criterion, lambda_l1,epoch):\n","\n","    l1_norm = 0\n","    for param in model.parameters():\n","        l1_norm += torch.sum(torch.abs(param))\n","    # Cross-entropy loss\n","    ce_loss = criterion(outputs, labels)\n","    # Total loss with L1 regularization\n","    total_loss = ce_loss - lambda_l1 * l1_norm\n","\n","    print(f\"\\n\\nThe l1 norm as loss : {l1_norm}\")\n","\n","    print(f\"Cross entropy loss : {ce_loss}\")\n","\n","    print(f\"Regularisation loss : (lambda_l1*l1_norm) {lambda_l1*l1_norm}\")\n","\n","    print(f\"Total loss : (ce_loss-lambda_l1*l1_norm) {total_loss}\")\n","\n","    writer.add_scalar('Loss/L1_norm', l1_norm, epoch)\n","    writer.add_scalar('Loss/Cross_entropy', ce_loss, epoch)\n","    writer.add_scalar('Loss/Regularisation', lambda_l1 * l1_norm, epoch)\n","    writer.add_scalar('Loss/Total', total_loss, epoch)\n","    return total_loss\n","\n","\n","# regularization_factor=0.1\n","# criterion = nn.CrossEntropyLoss()\n","# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n","# scheduler = StepLR(optimizer,step_size=1,gamma=0.7)\n","\n","def l1_norm(model):\n","    l1 = 0\n","    for param in model.parameters():\n","        l1 += torch.sum(torch.abs(param))\n","    return l1\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1dd3uzQXqlXu"},"outputs":[],"source":["\n","def train(model, criterion, optimizer, scheduler , train_loader, valid_loader, num_epochs, lambda_l1):\n","\n","    print(\"\\n\\nStarted training  \\n\")\n","    best_model = None\n","    best_accuracy = 0.0\n","\n","    for epoch in range(num_epochs):\n","        i=0\n","        start_time = time.time()\n","        model.train()\n","        running_loss = 0.0\n","        correct = 0\n","        total = 0\n","\n","        for batch_idx, (inputs, labels) in enumerate(train_loader):  # Added batch_idx for printing batch count\n","            optimizer.zero_grad()\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = model(inputs)\n","            loss = custom_loss(outputs, labels, model, criterion, lambda_l1)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item() * inputs.size(0)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","        scheduler.step()\n","        epoch_loss = running_loss / len(train_loader.dataset)\n","        epoch_acc = 100 * correct / total\n","\n","        valid_loss, valid_acc = evaluate(model, valid_loader, criterion)\n","        end_time=time.time()\n","        total_time=end_time-start_time\n","        # Print epoch loss and accuracy\n","\n","        print('\\nEpoch [{}/{}], Train Loss: {:.4f}, Train Accuracy: {:.2f}%, Valid Loss: {:.4f}, Valid Accuracy: {:.2f}%, Time: {:.2f}s'.format(\n","            epoch + 1, num_epochs, epoch_loss, epoch_acc, valid_loss, valid_acc,total_time))\n","        writer.add_scalar('Loss/Train', epoch_loss, epoch)\n","        writer.add_scalar('Accuracy/Train', epoch_acc, epoch)\n","        writer.add_scalar('Loss/Valid', valid_loss, epoch)\n","        writer.add_scalar('Accuracy/Valid', valid_acc, epoch)\n","\n","        if valid_acc \u003e best_accuracy:\n","            best_accuracy = valid_acc\n","            best_model = model.state_dict()\n","    print(\"best accuracy is \",best_accuracy)\n","    return model\n","\n","# def complete_train(model):\n","\n","#   l1_norm_outputs = calculate_l1_norm_of_outputs(model)\n","#   l1_norm_inputs = calculate_l1_norm_of_inputs(model)\n","#   threshold_outputs = calculate_threshold_l1_norm(l1_norm_outputs, pruning_rate)\n","#   threshold_inputs = calculate_threshold_l1_norm(l1_norm_inputs, pruning_rate)\n","\n","#   print(\"\\nBefore pruning:\\n\")\n","#   print_conv_layer_shapes(model)\n","\n","#   model=prune_model(model,pruning_rate,l1_norm_inputs,l1_norm_outputs,threshold_inputs,threshold_outputs)\n","\n","#   print(\"\\nAfter pruning:\\n\")\n","#   print_conv_layer_shapes(model)\n","\n","#   print(\"\\n Pruned Filter Sizes \\n\")\n","#   check_pruning(model)\n","\n","  # criterion = nn.CrossEntropyLoss()\n","  # optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n","  # scheduler = StepLR(optimizer,step_size=1,gamma=0.7)\n","\n","\n","\n","#   print(\"The model that we are using is \\n\",model)\n","#   l1_pre_maximising=l1_norm(model)\n","#   print(f\"\\n\\n Pre training L1 Norm: {l1_pre_maximising}\\n\\n\")\n","\n","# model=train(model, criterion, optimizer, scheduler, train_loader, valid_loader, num_epochs, lambda_l1 )\n","\n","#   l1_post_maximising=l1_norm(model)\n","#   print(f\"\\n\\nPost training L1 Norm: {l1_post_maximising}\\n\\n\")\n","\n","#   return model\n","\n","# def prune(model):\n","#    for _ in range(20):\n","#       complete_train(model)\n","\n","# prune(model)\n","# writer.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"0N0AVirIfXZ5"},"outputs":[],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GJZINL8kpBiC"},"outputs":[],"source":["model=DenseNet(Bottleneck, [6,12,24,16], growth_rate=32)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"aCkbF5eafonE"},"outputs":[],"source":["# model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bHKUBk9NPYzQ"},"outputs":[],"source":["def update_inputs_channels(bottleneck_layer,prev_channels):\n","  for name,module in bottleneck_layer.named_children():\n","    if isinstance(module,nn.Conv2d):\n","      in_channels=prev_channels\n","      module.weight.data = module.weight.data[:, :in_channels, :, :]\n","      module.in_channels=in_channels\n","      prev_channels=module.out_channels\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BeyP9MWFqoWa"},"outputs":[],"source":["def prune_filters_of_bottleneck(bottleneck_layer,threshold_values,next_input):\n","  next_channel=next_input\n","  for name,layer in bottleneck_layer.named_children():\n","    filters_to_remove=[]\n","    if isinstance(layer,nn.Conv2d):\n","      filters=layer.weight\n","      num_filters_to_prune=0\n","\n","      for idx, filter in enumerate(filters):\n","        l1_norm = torch.sum(torch.abs(filter)).item()\n","        # print(l1_norm)\n","        # print(threshold_values[name])\n","        # print(name)\n","        if l1_norm \u003c threshold_values[name]:\n","          num_filters_to_prune+=1\n","          layer.weight.data[idx].zero_()\n","          filters_to_remove.append(idx)\n","      if num_filters_to_prune \u003e 0:\n","        # print(\"The number of filters to prune are\",num_filters_to_prune)\n","        in_channels = next_channel\n","        out_channels = layer.out_channels - num_filters_to_prune\n","        # print(\"In channels are \",in_channels)\n","        # print(\"The out features originally are \",layer.out_channels)\n","        # print(\"Out channels are \",out_channels)\n","        # print(f\"Filters to prune are {num_filters_to_prune}\")\n","        # print(f\"The number of filters to prune are {filters_to_remove}\")\n","        # print(f\"Making a new layer for {layer}\")\n","        # print(f\"The in channels are {in_channels}\")\n","        # print(f\"The out channels are {out_channels}\")\n","        # print(f\"The filters to remove are {filters_to_remove}\")\n","        new_conv_layer=get_new_conv(in_channels,layer,0,filters_to_remove).to(device)\n","        # print(\"The new convolution layer is \",new_conv_layer)\n","        setattr(bottleneck_layer, name, new_conv_layer)\n","        next_channel=out_channels\n","\n","    elif isinstance(layer, nn.BatchNorm2d):\n","      new_batch_norm_2d_layer=nn.BatchNorm2d(num_features=next_channel).to(device)\n","      setattr(bottleneck_layer, name, new_batch_norm_2d_layer)\n","      del new_batch_norm_2d_layer\n","\n","    elif isinstance(layer,nn.Linear):\n","      in_channels=next_channel\n","      out_features=layer.out_features\n","      has_bias=True if layer.bias is not None else False\n","      new_linear_layer=nn.Linear(in_channels,out_features,bias=has_bias).to(device)\n","      # setattr(bottleneck_layer, name, new_linear_layer)\n","      del new_linear_layer\n","  return next_channel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EsGOa7fforuM"},"outputs":[],"source":["def prune_bottleneck(bottleneck_layer,prev):\n","  l1_norm_values=calculate_l1_norm_of_filters(bottleneck_layer)\n","  print(l1_norm_values)\n","  threshold_values=calculate_threshold_l1_norm_of_filters(l1_norm_values,pruning_rate)\n","  print(threshold_values)\n","  prev_out=prune_filters_of_bottleneck(bottleneck_layer,threshold_values,prev)\n","  update_inputs_channels(bottleneck_layer,prev)\n","  print(prev_out)\n","  return prev_out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fx7YAdkOdxzs"},"outputs":[],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GzpxvowqLy4X"},"outputs":[],"source":["len(model.dense1[0].conv1.weight.data)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"RpR2MbTTKm9Y"},"outputs":[],"source":["model.dense1[0].conv1.weight.data"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"I4Bp8rsO3Zfv"},"outputs":[],"source":["times=0\n","prev_t=0\n","for name,layer in model.named_children():\n","  if isinstance(layer,nn.Conv2d):\n","    # print(layer)\n","    prev_t=layer.out_channels\n","    print()\n","    # print(next_input)\n","    print()\n","  elif isinstance(layer,nn.BatchNorm2d):\n","    # print(layer)\n","    new_batch_norm_2d_layer=nn.BatchNorm2d(num_features=prev_t).to(device)\n","    setattr(model,name,new_batch_norm_2d_layer)\n","    print()\n","  elif isinstance(layer,nn.Linear):\n","    new_layer=nn.Linear(in_features=prev_t,out_features=layer.out_features,bias=True).to(device)\n","    setattr(model,name,new_layer)\n","    # print(layer)\n","    print()\n","  elif isinstance(layer,Transition):\n","    for n,module in layer.named_children():\n","      if isinstance(module, nn.BatchNorm2d):\n","        print(\"The input channel is \",prev_t)\n","        new_batch_norm_2d_layer=nn.BatchNorm2d(num_features=prev_t).to(device)\n","        setattr(layer,n,new_batch_norm_2d_layer)\n","\n","        print()\n","      elif isinstance(module,nn.Conv2d):\n","        print(\"The input channel is \",prev_t)\n","        new_conv = nn.Conv2d(\n","                    in_channels=prev_t,  # Set to prev_t which is the updated number of input channels\n","                    out_channels=module.out_channels,\n","                    kernel_size=module.kernel_size,\n","                    stride=module.stride,\n","                    padding=module.padding,\n","                    dilation=module.dilation,\n","                    groups=module.groups,\n","                    bias=module.bias is not None\n","                ).to(device)\n","\n","\n","\n","        setattr(layer, n, new_conv)\n","        prev_t=module.out_channels\n","  elif isinstance(layer,nn.Sequential):\n","    for n,module in layer.named_children():\n","      if isinstance(module, Bottleneck):\n","        print(\"Pruning only for \",module)\n","        prev_out=prune_bottleneck(module,prev_t)\n","        prev_t+=prev_out\n","\n","    #     # break\n","        # print(\"new\")\n","  # if times==1:\n","  #    break\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G1ouuyHVn5aP"},"outputs":[],"source":["# for name, module in model.named_modules():\n","#   print()\n","#     if name.startswith('dense1') or name.startswith('dense2') or name.startswith('dense3'):\n","#         print(f\" {name}:\")\n","#         for sub_name, sub_module in module.named_children():\n","#             print(f\" 1{sub_name}: {sub_module}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ryDMKo9o82i"},"outputs":[],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"LMnwxK9I6aKv"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","Started training  \n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]}],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n","scheduler = StepLR(optimizer,step_size=1,gamma=0.7)\n","\n","model=train(model, criterion, optimizer, scheduler, train_loader, valid_loader, num_epochs, lambda_l1 )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aeeTeYi-L6me"},"outputs":[],"source":["len(model.dense1[0].conv1.weight.data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o3E0RWjfK0Yv"},"outputs":[],"source":["model.dense1[0].conv1.weight.data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lmj7kjTg3avu"},"outputs":[],"source":["model.dense1[0].conv1.weight.data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BVkOlNO5HSdx"},"outputs":[],"source":["model.dense1[0].conv2.weight.data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5aTcsJbKH6kP"},"outputs":[],"source":["model.dense1[1].conv1.weight.data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HLyhK0MMIJq-"},"outputs":[],"source":["model.dense1[1].conv2.weight.data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"5EicU_r03bFO"},"outputs":[],"source":["input_tensor = torch.randn(1, 3, 572, 572)\n","\n","\n","def print_size(module, input, output):\n","    print(f\"{module.__class__.__name__} output size: {output.size()}\")\n","\n","\n","for layer in model.children():\n","    layer.register_forward_hook(print_size)\n","\n","\n","with torch.no_grad():\n","    output = model(input_tensor)\n","\n","print(\"Final output size:\", output.size())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IfGLQM4arW3n"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Define a sample input tensor\n","sample_input = torch.randn(1, 3, 32, 32)  # Assuming input size is 32x32 with 3 channels\n","\n","# Initialize your DenseNet model\n","# model = DenseNet()\n","\n","# Perform a forward pass\n","output = model(sample_input)\n","print(\"Output shape: \", output.shape)\n","\n","# Define a simple loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Dummy target\n","target = torch.tensor([0])  # Assuming a single-class output for simplicity\n","\n","# Perform a forward pass\n","output = model(sample_input)\n","\n","# Compute loss\n","loss = criterion(output, target)\n","print(\"Loss: \", loss.item())\n","\n","# Perform a backward pass\n","optimizer.zero_grad()\n","loss.backward()\n","\n","# Check gradients\n","for name, param in model.named_parameters():\n","    if param.grad is not None:\n","        print(f\"{name} gradient: {param.grad.sum().item()}\")\n","\n","# Perform a training step\n","optimizer.step()\n","\n","# Ensure no errors occurred during the forward and backward passes\n","print(\"Model forward and backward pass successful.\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOidWTp7zwYL0r6J1xi6yOY","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}